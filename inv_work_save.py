import pinocchio as pin
import numpy as np
import pandas as pd
import pinocchio as pin
from pinocchio.visualize import MeshcatVisualizer
import meshcat.geometry as g
import meshcat.transformations as tf
import time  # ç”¨äºæš‚åœè§‚å¯Ÿ

# # --- æ·»åŠ ä»¥ä¸‹ä¸¤è¡Œä»£ç è¿›è¡Œè°ƒè¯• ---
# print(f"DEBUG: Pinocchio version loaded by script: {pin.__version__}")
# print(f"DEBUG: Pinocchio module path loaded by script: {pin.__file__}")
# --- è°ƒè¯•ä»£ç ç»“æŸ ---
# import pinocchio as pin
# print(hasattr(pin, 'normalize'))

def load_robot_model(urdf_path): #/home/tracy/airexo/AirExo-2/airexo/urdf_models/robot
    robot_dir = "/home/ryan/Documents/GitHub/AirExo-2-test/airexo/urdf_models/robot"
    
    # å°†robotç›®å½•æœ¬èº«ä½œä¸ºåŒ…ç›®å½•ï¼Œè¿™æ ·Pinocchioå¯ä»¥æ‰¾åˆ°ç›¸å¯¹è·¯å¾„çš„ç½‘æ ¼æ–‡ä»¶
    model, collision_model, visual_model = pin.buildModelsFromUrdf(
        urdf_path,
        package_dirs=[robot_dir],
        geometry_types=[pin.GeometryType.COLLISION, pin.GeometryType.VISUAL]
    )
    data = model.createData()
    return model, data, collision_model, visual_model


def read_csv_data(file_path):
    data = pd.read_csv(file_path)
    positions = data[['x', 'y', 'z']].values
    euler_angles_deg = data[['rx', 'ry', 'rz']].values
    euler_angles_rad = np.deg2rad(euler_angles_deg)  # ç»Ÿä¸€è½¬å¼§åº¦
    return positions, euler_angles_rad

import pinocchio as pin
import numpy as np

def compute_ik(model, data, target_position, target_euler_angles, q_init, active_idxs, 
             max_iter=2000, eps=0.08, stall_threshold=50, damp_base=1e-3, alpha=0.1): # å¢åŠ alphaå‚æ•°
    """
    ä½¿ç”¨é˜»å°¼æœ€å°äºŒä¹˜æ³•ï¼ˆDLSï¼‰æ±‚è§£é€†è¿åŠ¨å­¦ (ä¿®æ­£ç‰ˆ)
    """
    end_effector_name = "r_gripper_base_link"
    frame_id = model.getFrameId(end_effector_name)
    if frame_id < 0 or frame_id >= len(model.frames):
        raise ValueError(f"End effector frame '{end_effector_name}' not found")

    target_rotation = pin.rpy.rpyToMatrix(target_euler_angles)
    target_pose = pin.SE3(target_rotation, target_position)

    q = q_init.copy()
    pin.forwardKinematics(model, data, q)
    pin.updateFramePlacements(model, data)
    current_pose = data.oMf[frame_id]
    
    print("\n--- IK æ±‚è§£å¼€å§‹ ---")
    print(f"ç›®æ ‡ä½ç½®: {target_position}, ç›®æ ‡æ¬§æ‹‰è§’: {target_euler_angles}")
    print(f"åˆå§‹æœ«ç«¯ä½ç½®: {current_pose.translation}, åˆå§‹æ¬§æ‹‰è§’: {pin.rpy.matrixToRpy(current_pose.rotation)}")

    prev_error_norm = float('inf')
    stall_count = 0
    best_q = q.copy()
    min_error = np.linalg.norm(pin.log(target_pose.inverse() * current_pose).vector)

    for i in range(max_iter):
        pin.forwardKinematics(model, data, q)
        pin.updateFramePlacements(model, data)
        current_pose = data.oMf[frame_id]

        error_vec = pin.log(target_pose.inverse() * current_pose).vector
        error_norm = np.linalg.norm(error_vec)

        if error_norm < min_error:
            min_error = error_norm
            best_q = q.copy()

        if error_norm < eps:
            print(f"âœ… IK æ”¶æ•›ï¼Œç¬¬ {i} æ¬¡è¿­ä»£ï¼Œè¯¯å·®: {error_norm:.6f}")
            return True, q, error_norm

        if abs(error_norm - prev_error_norm) < 1e-6: # ä¿®æ”¹æ—©åœåˆ¤æ–­ï¼ŒåŸºäºè¯¯å·®å˜åŒ–é‡
            stall_count += 1
            if stall_count > stall_threshold:
                print(f"âš ï¸ IK æ—©åœï¼ˆè¯¯å·®ä¸å†å‡å°ï¼‰ï¼Œç¬¬ {i} æ¬¡è¿­ä»£ï¼Œå½“å‰è¯¯å·®: {error_norm:.6f}, æœ€ä½³è¯¯å·®: {min_error:.6f}")
                return False, best_q, min_error
        else:
            stall_count = 0

        prev_error_norm = error_norm

        J = pin.computeFrameJacobian(model, data, q, frame_id)
        J_active = J[:, active_idxs]

        damp = min(max(damp_base, error_norm * 0.05), 0.05)
        JJt = J_active @ J_active.T + damp * np.eye(6)
        
        # error_vec æ˜¯ä» target åˆ° current çš„å˜æ¢ï¼Œæˆ‘ä»¬éœ€è¦æœåæ–¹å‘ç§»åŠ¨æ¥å‡å°å®ƒ
        dq_active = J_active.T @ np.linalg.solve(JJt, error_vec)

        dq = np.zeros(model.nv)
        dq[active_idxs] = dq_active

        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨å¸¦æ­¥é•¿çš„è´Ÿæ–¹å‘æ›´æ–°
        q = pin.integrate(model, q, -alpha * dq)
        
        q[active_idxs] = np.clip(q[active_idxs], model.lowerPositionLimit[active_idxs], model.upperPositionLimit[active_idxs])
        if hasattr(pin, 'normalize'):
            q[active_idxs] = pin.normalize(model, q)[active_idxs]

    print(f"âš ï¸ IK æœªæ”¶æ•›ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•° {max_iter}ï¼Œæœ€ç»ˆè¯¯å·®: {error_norm:.6f}, æœ€ä½³è¯¯å·®: {min_error:.6f}")
    return False, best_q, min_error


def select_best_solution_by_error(solutions, errors, q_previous, active_idxs, per_joint_max_delta, total_max_delta, lambda_weight):
    valid_solutions = []
    valid_errors = []
    valid_delta_norms = []
    
    for q_ik, err in zip(solutions, errors):
        delta_q = q_ik[active_idxs] - q_previous[active_idxs]
        delta_q_norm = np.linalg.norm(delta_q)  # æ€»èŒƒæ•°
        max_delta_per_joint = np.max(np.abs(delta_q))  # æœ€å¤§å•ä¸ªå…³èŠ‚å˜åŒ–
        
        if max_delta_per_joint <= per_joint_max_delta and delta_q_norm <= total_max_delta:
            valid_solutions.append(q_ik)
            valid_errors.append(err)
            valid_delta_norms.append(delta_q_norm)
    
    if valid_solutions:
        # åœ¨æœ‰æ•ˆè§£ä¸­ï¼Œé€‰æ‹©æœ€å°åŒ– (error + lambda * delta_norm)
        scores = [err + lambda_weight * delta for err, delta in zip(valid_errors, valid_delta_norms)]
        min_score_idx = np.argmin(scores)
        print(f"Selected solution with error: {valid_errors[min_score_idx]}, delta_norm: {valid_delta_norms[min_score_idx]}")
        return valid_solutions[min_score_idx], valid_errors[min_score_idx]
    else:
        # Fallback: å¦‚æœæ— æœ‰æ•ˆè§£ï¼Œé€‰min(error)ï¼Œä½†æ‰“å°è­¦å‘Š
        min_error_idx = np.argmin(errors)
        print(f"âš ï¸ No valid solutions within delta limits, falling back to min error: {errors[min_error_idx]}")
        return solutions[min_error_idx], errors[min_error_idx]



# def show_camera_axes(viz, model, data, q_current, camera_link_name="camera_link", axis_length=0.15, set_camera_view=True):
#     """
#     åœ¨ Meshcat ä¸­æ˜¾ç¤ºæŒ‡å®šç›¸æœº link çš„åæ ‡ç³»ï¼Œå¹¶è®¾ç½®å¯è§†åŒ–è§†è§’ä¸ºç›¸æœºè§†è§’ã€‚
    
#     å‚æ•°ï¼š
#         viz: MeshcatVisualizer å¯¹è±¡
#         model: Pinocchio æœºå™¨äººæ¨¡å‹
#         data: Pinocchio æœºå™¨äººæ•°æ®
#         q_current: å½“å‰å…³èŠ‚è§’ numpy æ•°ç»„
#         camera_link_name: ç›¸æœºå¯¹åº”çš„ link åç§°
#         axis_length: åæ ‡è½´é•¿åº¦
#         set_camera_view: æ˜¯å¦è‡ªåŠ¨è®¾ç½®ä¸ºç›¸æœºè§†è§’
#     """
    
#     # 1. è·å–ç›¸æœº link ä½å§¿
#     camera_link_id = model.getFrameId(camera_link_name)
#     pin.forwardKinematics(model, data, q_current)
#     pin.updateFramePlacements(model, data)
#     camera_se3 = data.oMf[camera_link_id]
#     T_world_camera = np.array(camera_se3.homogeneous)  # 4x4 numpy çŸ©é˜µ
#     print(f"{camera_link_name} ä½å§¿:\n{T_world_camera}")
    
#     # 2. ç»˜åˆ¶åæ ‡è½´
#     x_points = np.array([[0, axis_length], [0, 0], [0, 0]])
#     y_points = np.array([[0, 0], [0, axis_length], [0, 0]])
#     z_points = np.array([[0, 0], [0, 0], [0, axis_length]])
    
#     viz.viewer["camera_axes/x"].set_object(
#         g.Line(g.PointsGeometry(x_points), g.MeshBasicMaterial(color=0xff0000))
#     )
#     viz.viewer["camera_axes/y"].set_object(
#         g.Line(g.PointsGeometry(y_points), g.MeshBasicMaterial(color=0x00ff00))
#     )
#     viz.viewer["camera_axes/z"].set_object(
#         g.Line(g.PointsGeometry(z_points), g.MeshBasicMaterial(color=0x0000ff))
#     )
    
#     # 3. è®¾ç½®åæ ‡è½´ä½å§¿
#     viz.viewer["camera_axes/x"].set_transform(T_world_camera)
#     viz.viewer["camera_axes/y"].set_transform(T_world_camera)
#     viz.viewer["camera_axes/z"].set_transform(T_world_camera)
    
#     if set_camera_view:
#         # 4. è®¾ç½® Meshcat è§†è§’ä¸ºæœºå™¨äººç›¸æœºè§†è§’
#         position = camera_se3.translation
#         rotation = camera_se3.rotation
        
#         # ROS ç›¸æœºåæ ‡ç³»ï¼šz å‰å‘ï¼Œx å³å‘ï¼Œy ä¸‹å‘
#         # å¯¹äº Meshcat ç›¸æœºè§†è§’ï¼Œæˆ‘ä»¬éœ€è¦ï¼š
#         # - forwardï¼šç›¸æœºçœ‹å‘çš„æ–¹å‘ï¼ˆç›¸æœº z è½´æ­£æ–¹å‘ï¼‰
#         # - upï¼šç›¸æœºçš„ä¸Šæ–¹å‘ï¼ˆç›¸æœº -y è½´æ–¹å‘ï¼Œå› ä¸º ROS ç›¸æœº y è½´å‘ä¸‹ï¼‰
        
#         forward_local = np.array([0.0, -1.0, 0.0])  # ç›¸æœºæœ¬åœ°åæ ‡ç³» z è½´
#         up_local = np.array([0.0, 0.0, 1.0])      # ç›¸æœºæœ¬åœ°åæ ‡ç³» -y è½´
        
#         # å¯é€‰ï¼šæ·»åŠ å‘ä¸‹å€¾æ–œè§’åº¦æ¥æ›´å¥½åœ°è§‚å¯Ÿæœºå™¨äºº
#         tilt_angle = 0 * np.pi / 180  # -30Â° å‘ä¸‹å€¾æ–œï¼Œå¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼
#         if tilt_angle != 0:
#             # ç»•ç›¸æœº x è½´æ—‹è½¬ï¼ˆä¿¯ä»°ï¼‰
#             cos_t, sin_t = np.cos(tilt_angle), np.sin(tilt_angle)
#             R_tilt = np.array([
#                 [1.0, 0.0, 0.0],
#                 [0.0, cos_t, -sin_t],
#                 [0.0, sin_t, cos_t]
#             ])
#             forward_local = R_tilt @ forward_local
#             up_local = R_tilt @ up_local
        
#         # è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
#         forward_world = rotation @ forward_local
#         up_world = rotation @ up_local


#         # try:
#         viz.viewer[camera_link_name].set_property("visible", False)
#         # except Exception as e:
#         #     print(f"Warning: Unable to set property for {camera_link_name}. Error: {e}")

#         # # å…³é”®ä¿®æ”¹ï¼šå°†ç›¸æœºä½ç½®ç¨å¾®å‘åç§»åŠ¨ï¼Œé¿å…åœ¨å¤´éƒ¨å†…éƒ¨
#         # offset_distance = 0.1  # å‘ååç§»è·ç¦»ï¼Œå¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼
#         # camera_position = position + forward_world * offset_distance  # ç›¸æœºç¨å¾®å‘å
#         lookat_distance = 1.0  # çœ‹å‘å‰æ–¹çš„è·ç¦»
#         lookat = np.array([0.0, 1.0, 0.0]) # çœ‹å‘å¤´éƒ¨å‰æ–¹

#         camera_position = np.array([-0.0032391, -0.590296, 2.502606])  # éšæœºç¤ºä¾‹åæ ‡ï¼Œä½ å¯ä»¥æ›¿æ¢ä¸ºæ‰€éœ€å€¼

#         print(f"è®¾ç½®ç›¸æœºè§†è§’:")
#         print(f"  ä½ç½®: {position}")
#         print(f"  çœ‹å‘: {lookat}")
#         print(f"  ä¸Šæ–¹å‘: {up_world}")

#         # è®¡ç®—ç›¸æœºå‰å‘å‘é‡å’Œä¸Šå‘å‘é‡
#         forward_vector = lookat - position
#         forward_vector /= np.linalg.norm(forward_vector)  # å•ä½åŒ–
#         up_vector = up_world / np.linalg.norm(up_world)  # å•ä½åŒ–

#         #     # è®¾ç½®ç›¸æœºä½ç½®å’Œæ–¹å‘
#         # viz.viewer["/Cameras/default"].set_property("position", camera_position.tolist())
#         # viz.viewer["/Cameras/default/rotated/<object>"].set_property("position", [0, 0, 0])
#         # viz.viewer["/Cameras/default/rotated/<object>"].set_property("up", up_world.tolist())        
#         # viz.viewer["/Cameras/default/rotated/<object>"].set_property("forward", forward_vector.tolist())
            
#         lookat_distance = 1.0  # çœ‹å‘å‰æ–¹çš„è·ç¦»
#         lookat_target = camera_position + forward_world * lookat_distance
#         # æ”¾å¤§ä¸€äº›é•¿åº¦ç”¨äºå¯è§†åŒ–
#         vec_len = 0.3
#         forward_points = np.array([
#             [0, forward_vector[0]*vec_len],
#             [0, forward_vector[1]*vec_len],
#             [0, forward_vector[2]*vec_len]
#         ])
#         up_points = np.array([
#             [0, up_vector[0]*vec_len],
#             [0, up_vector[1]*vec_len],
#             [0, up_vector[2]*vec_len]
#         ])

#         # åœ¨ç›¸æœºä½ç½®å¤„ç»˜åˆ¶æœå‘ç®­å¤´
#         viz.viewer["camera_dir/forward"].set_object(
#             g.Line(g.PointsGeometry(forward_points), g.MeshBasicMaterial(color=0xff0000))
#         )
#         viz.viewer["camera_dir/forward"].set_transform(tf.translation_matrix(camera_position))

#         # viz.viewer["camera_dir/up"].set_object(
#         #     g.Line(g.PointsGeometry(up_points), g.MeshBasicMaterial(color=0x00ff00))
#         # )
#         # viz.viewer["camera_dir/up"].set_transform(tf.translation_matrix(new_position))

        
#         # åœ¨å¤´éƒ¨ç›¸æœºå‰æ–¹æ”¾ç½®ä¸€ä¸ªé»„è‰²çƒ
#         ball_distance = 0.5  # çƒè·ç¦»ç›¸æœºçš„è·ç¦»
#         ball_position = position + forward_world * ball_distance

#         # è®¾ç½®çƒä½“å¯¹è±¡
#         viz.viewer["camera_ball"].set_object(
#             g.Sphere(0.05), g.MeshLambertMaterial(color=0xffff00, opacity=0.8)
#         )
#         viz.viewer["camera_ball"].set_transform(tf.translation_matrix(ball_position))

#         print(f"åœ¨å¤´éƒ¨ç›¸æœºç»¿è‰²åæ ‡è½´çš„åæ–¹å‘æ”¾ç½®é»„è‰²çƒï¼Œä½ç½®: {ball_position}")
#         # è®¾ç½®ç›¸æœºè§†è§’ â€”â€” å§‹ç»ˆçœ‹å‘é»„è‰²å°çƒ

#         camera_pos = np.array([-0.0032, -0.2903, 1.5026])
#         target_pos = np.array([-0.0032, -0.5903, 1.5026])

#         # 1. è®¾ç½®ç„¦ç‚¹
#         T = np.eye(4)
#         T[:3, 3] = target_pos  # ç„¦ç‚¹åœ¨ target_pos
#         # viz.viewer["/Cameras/default"].set_transform(T)
#         # 2. è®¾ç½®ç›¸æœºç›¸å¯¹ç„¦ç‚¹çš„åç§»
#         offset = camera_pos - target_pos
#         # viz.viewer["/Cameras/default/rotated/<object>"].set_property("position", offset.tolist())
#         # viz.viewer["/Cameras/default"].set_property("position", camera_position.tolist())
#         # viz.viewer["/Cameras/default"].set_property("target", camera_target.tolist())
#         # viz.viewer["/Cameras/default/rotated/<object>"].set_property("up", up_world.tolist())
#         look_at(viz,
#         camera_pos=[-0.0032, 0.2, 1.7526],
#         target_pos=[-0.0032, -0.5903, 1.5026])


def look_at(viz, camera_pos, target_pos, up=np.array([0, 0, 1])):
    camera_pos = np.array(camera_pos)
    target_pos = np.array(target_pos)
    
    # è®¾ç½®ç„¦ç‚¹
    T = np.eye(4)
    T[:3, 3] = target_pos
    viz.viewer["/Cameras/default"].set_transform(T)

    # ç›¸æœºç›¸å¯¹ç„¦ç‚¹çš„åç§»
    offset = camera_pos - target_pos
    viz.viewer["/Cameras/default/rotated/<object>"].set_property("position", offset.tolist())

    # ---- å…³é”®ï¼šä¿®æ­£æ—‹è½¬ï¼Œä½¿ç›¸æœºçœŸçš„çœ‹å‘ç›®æ ‡ ----
    # forward = -Z æ–¹å‘
    forward = (target_pos - camera_pos)
    forward /= np.linalg.norm(forward)

    right = np.cross(up, forward)
    right /= np.linalg.norm(right)

    true_up = np.cross(forward, right)


    R = np.eye(4)
    R[:3, 0] = right
    R[:3, 1] = true_up
    R[:3, 2] = -forward   # æ³¨æ„è¿™é‡Œæ˜¯ +Z/-Zï¼Œå¯èƒ½éœ€è¦ flip


    viz.viewer["/Cameras/default/rotated"].set_transform(R)

def main():
    urdf_path = "/home/ryan/Documents/GitHub/AirExo-2-test/airexo/urdf_models/robot/true_robot.urdf"
    csv_file_path = "/home/ryan/Documents/GitHub/AirExo-2-test/train_video/hand_landmarks_3d_offline.csv"

    # æ¥æ”¶æ‰€æœ‰å››ä¸ªå¯¹è±¡
    model, data, collision_model, visual_model = load_robot_model(urdf_path)
    active_joints = ['r_joint1', 'r_joint2', 'r_joint3', 'r_joint4', 'r_joint5', 'r_joint6', 'r_joint7']
    active_idxs = []
    for name in active_joints:
        jid = model.getJointId(name)
        if jid < model.njoints:
            idx_q = model.joints[jid].idx_q
            for i in range(model.joints[jid].nq):
                active_idxs.append(idx_q + i)
        else:
            raise ValueError(f"Joint '{name}' not found in model.")

    print(f"æ´»è·ƒå…³èŠ‚ç´¢å¼•: {active_idxs}")
    print(f"æ´»è·ƒå…³èŠ‚æ•°é‡: {len(active_idxs)} (åº”ä¸º7)")
    # æ–°å¢ï¼šæ¯å¸§å…³èŠ‚å˜åŒ–çº¦æŸ
    per_joint_max_delta = 0.15 #0.0873 # æ¯ä¸ªå…³èŠ‚æœ€å¤§å…è®¸å˜åŒ–ï¼ˆå¼§åº¦ï¼‰ï¼Œæ ¹æ®è‡‚é€Ÿåº¦è°ƒæ•´
    total_max_delta = 0.4 #0.23      # æ‰€æœ‰æ´»è·ƒå…³èŠ‚å˜åŒ–èŒƒæ•°çš„æœ€å¤§å…è®¸å€¼
    lambda_weight = 0.1        # åŠ æƒdelta_qçš„æƒé‡ï¼ˆç”¨äºæœ€å°åŒ– error + lambda * delta_normï¼‰

    # --- æ–°å¢ï¼šä¸ºIKæ±‚è§£å®šä¹‰éšæœºå™ªå£°å¹…åº¦ ---
    noise_level = 0.2 #0.1 # éšæœºå™ªå£°çš„å¹…åº¦ï¼ˆå¼§åº¦ï¼‰ï¼Œå¯ä»¥è°ƒæ•´è¿™ä¸ªå€¼

    # 3. å¢åŠ å°è¯•æ¬¡æ•°ï¼šè¿›è¡Œæ›´å¹¿æ³›çš„æœç´¢
    ik_attempts = 20              # åœ¨ä¸‹é¢çš„ for å¾ªç¯ä¸­ä½¿ç”¨è¿™ä¸ªå˜é‡ï¼ŒåŸä¸º 10 æ¬¡

    # æ‰‹åŠ¨è®¾ç½®ç›¸æœºåˆ°ä¸–ç•Œåæ ‡ç³»çš„è½¬æ¢çŸ©é˜µ
    t_base_cam = np.array([0.3,-0.85,1.41])  # å•ä½ï¼šç±³
    rpy = np.array([np.deg2rad(90), 0.0, np.deg2rad(-90)])  # å¼§åº¦
    R_base_cam = pin.rpy.rpyToMatrix(rpy)  # åŒ…å« z è½´ç¿»è½¬
    camera_pose = pin.SE3(R_base_cam, t_base_cam)
    print("T_base_cam (æ‰‹åŠ¨å†™æ­»):\n", camera_pose.homogeneous)

    wrist_positions, wrist_euler_angles = read_csv_data(csv_file_path)

    # åˆå§‹åŒ– Meshcat å¯è§†åŒ–
    viz = MeshcatVisualizer(model, collision_model, visual_model)
    viz.initViewer()
    viz.loadViewerModel()  # åŠ è½½ URDF åˆ°æµè§ˆå™¨
    
    viz.viewer.open()
    q_current = pin.neutral(model)  # åˆå§‹ q

    look_at(viz,camera_pos=[-0.0032, -0.19,1.6526],target_pos=[-0.0032, -0.3903, 1.6026])


    # è°ƒè¯•ï¼šæ‰“å° CSV æ•°æ®
    print(f"CSV positions (first 5): {wrist_positions[:5]}")
    print(f"CSV euler angles (first 5): {wrist_euler_angles[:5]}")
    print(f"Number of joints (nq): {model.nq}")
    
    # æ›¿æ¢åŸæœ‰q_initï¼šè‡ªå®šä¹‰è‡ªç„¶å‘å‰ä¼¸å±•åˆå§‹å§¿æ€
    q_start_values = np.array([1.2, 1.21,0.82,0.56, 0, 0.0, 0.0])
    q_start = np.zeros(model.nq)  # å…¨é›¶åŸºåº•
    q_start[active_idxs] = np.clip(q_start_values, model.lowerPositionLimit[active_idxs], model.upperPositionLimit[active_idxs])
    q_current = q_start.copy()  # ç”¨è‡ªå®šä¹‰åˆå§‹æ›¿æ¢
    print(f"è‡ªå®šä¹‰åˆå§‹å…³èŠ‚è§’åº¦ (è‡ªç„¶å‘å‰ä¼¸å±•): {q_start[active_idxs]}")

    print("\n--- IK åŠŸèƒ½å¥å…¨æ€§æµ‹è¯• ---")
    # åœ¨ for å¾ªç¯å‰ï¼Œç”¨äºæµ‹è¯•
    test_pos = np.array([0.6, 0.0, 1.2]) # æ­£å‰æ–¹ 0.5mï¼Œé«˜åº¦ 1.2m
    test_rot = pin.rpy.rpyToMatrix(0, 0, 0) # æ— æ—‹è½¬
    test_q_init = pin.neutral(model)
    success, q_sol, err = compute_ik(model, data, test_pos, pin.rpy.matrixToRpy(test_rot), test_q_init, active_idxs)
    if success:
        print("âœ… æµ‹è¯•ç›®æ ‡å¯è¾¾ï¼ŒIKæ±‚è§£å™¨å·¥ä½œæ­£å¸¸ï¼")
        # (å¯é€‰) åœ¨å¯è§†åŒ–ä¸­æ˜¾ç¤ºæµ‹è¯•ç»“æœï¼Œä»¥ç›´è§‚ç¡®è®¤
        viz.display(q_sol)
        print("åœ¨å¯è§†åŒ–çª—å£ä¸­æ˜¾ç¤ºæµ‹è¯•ç»“æœï¼Œ5ç§’åç»§ç»­å¤„ç†CSVè½¨è¿¹...")
        time.sleep(5)
    else:
        print("âŒ æµ‹è¯•ç›®æ ‡ä¸å¯è¾¾ï¼Œè¯·æ£€æŸ¥IKç®—æ³•æˆ–æ¨¡å‹ï¼")
    print("--- æµ‹è¯•ç»“æŸ ---\n")



    # æ–°å¢ï¼šåˆå§‹æ˜¾ç¤º neutral å§¿æ€ + ç¬¬ä¸€ä¸ªç›®æ ‡çƒä½“/è½´ï¼Œå¹¶æš‚åœ
    if len(wrist_positions) > 0:
        first_position = wrist_positions[0]
        first_euler_angles = wrist_euler_angles[0]
        
        first_local_position = np.array(first_position)
        first_world_position = camera_pose.act(first_local_position)
        
        first_local_rotation = pin.rpy.rpyToMatrix(first_euler_angles)
        first_world_rotation = camera_pose.rotation @ first_local_rotation
        
        print(f"åˆå§‹è½¬æ¢åä¸–ç•Œä½ç½®: {first_world_position}")
        print(f"åˆå§‹è½¬æ¢åä¸–ç•Œæ—‹è½¬çŸ©é˜µ: {first_world_rotation}")
        
        viz.display(q_current)
        
        target_pose = pin.SE3(first_world_rotation, first_world_position)
        
        viz.viewer["target_sphere"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0xff0000, opacity=0.8))
        viz.viewer["target_sphere"].set_transform(tf.translation_matrix(first_world_position))
        
        axis_length = 0.15
        x_points = np.array([[0, axis_length], [0, 0], [0, 0]])
        y_points = np.array([[0, 0], [0, axis_length], [0, 0]])
        z_points = np.array([[0, 0], [0, 0], [0, axis_length]])
        
        viz.viewer["target_axes/x"].set_object(g.Line(g.PointsGeometry(x_points), g.MeshBasicMaterial(color=0xff0000)))
        viz.viewer["target_axes/y"].set_object(g.Line(g.PointsGeometry(y_points), g.MeshBasicMaterial(color=0xffff00)))
        viz.viewer["target_axes/z"].set_object(g.Line(g.PointsGeometry(z_points), g.MeshBasicMaterial(color=0x0000ff)))
        
        target_tf = target_pose.homogeneous
        viz.viewer["target_axes/x"].set_transform(target_tf)
        viz.viewer["target_axes/y"].set_transform(target_tf)
        viz.viewer["target_axes/z"].set_transform(target_tf)
        
        print("åˆå§‹çŠ¶æ€è§‚å¯Ÿä¸­ï¼šæœºæ¢°è‡‚ (è‡ªå®šä¹‰è‡ªç„¶å§¿æ€) ä¸ç¬¬ä¸€ä¸ªç›®æ ‡ (çº¢è‰²çƒä½“åŠåæ ‡è½´) çš„å·®è·ã€‚")
        print(f"åˆå§‹çº¢è‰²å°çƒä½ç½® (æœ¬åœ°): {first_position}")
        print(f"åˆå§‹çº¢è‰²å°çƒä½ç½® (ä¸–ç•Œ): {first_world_position}")
        time.sleep(3)


    for i, (position, euler_angles) in enumerate(zip(wrist_positions, wrist_euler_angles)):
        print(f"\nProcessing frame {i}: Position={position}, Euler angles={euler_angles}")

        local_position = np.array(position)
        world_position = camera_pose.act(local_position)
        local_rotation = pin.rpy.rpyToMatrix(euler_angles)
        world_rotation = camera_pose.rotation @ local_rotation
        world_euler_angles = pin.rpy.matrixToRpy(world_rotation)
        
        print(f"è½¬æ¢åä¸–ç•Œä½ç½®: {world_position}")
        print(f"è½¬æ¢åä¸–ç•Œæ—‹è½¬çŸ©é˜µ: {world_rotation}")
       
        if i == 0:
            print(f"ç¬¬ä¸€å¸§ä½¿ç”¨è‡ªå®šä¹‰åˆå§‹å‰3å…³èŠ‚: {q_current[active_idxs[:3]]} (å·²ç²—ç•¥æŒ‡å‘ç›®æ ‡)")
            viz.display(q_current)
            print("æ˜¾ç¤ºè‡ªå®šä¹‰åˆå§‹å§¿æ€ï¼ˆç²—ç•¥æŒ‡å‘ç›®æ ‡ï¼‰ï¼Œè§‚å¯Ÿä¸ç›®æ ‡å·®è·ã€‚")
            time.sleep(3)
            
            q_previous = q_start.copy()
            
            active_ik_idxs = active_idxs[3:]
            solutions = []
            errors = []
            for _ in range(1):
                success, q_ik, err = compute_ik(model, data, world_position, world_euler_angles, q_current.copy(), active_ik_idxs)
                if success:
                    solutions.append(q_ik)
                    errors.append(err)
            
            if solutions:
                q_current, error = select_best_solution_by_error(solutions, errors, q_previous, active_idxs, per_joint_max_delta, total_max_delta, lambda_weight)
                # ğŸ”§ ä¿è¯éæœºæ¢°è‡‚å…³èŠ‚ä¸åŠ¨
                mask = np.ones(model.nq, dtype=bool)
                mask[active_idxs] = False
                q_current[mask] = q_start[mask]                
                print(f"ç¬¬ä¸€å¸§å4å…³èŠ‚ä¼˜åŒ–å: {q_current[active_idxs[3:]]}")
            else:
                print("ç¬¬ä¸€å¸§IKæ— è§£ï¼Œä½¿ç”¨fallbackã€‚")
                q_current = q_previous.copy()

        else:
            # åç»­å¸§ï¼šç»§æ‰¿ä¸Šä¸€å¸§qï¼Œä¼˜åŒ–æ‰€æœ‰å…³èŠ‚ï¼Œå¤šæ¬¡å°è¯•é€‰æœ€ä½³
            q_previous = q_current.copy()
            solutions = []
            errors = []
            
            # --- æ–¹æ¡ˆä¸€ä¿®æ”¹å¼€å§‹ ---
            for _ in range(ik_attempts): # åŸä¸º range(10)
        # ä¸ºåˆå§‹çŒœæµ‹æ·»åŠ éšæœºå™ªå£°ï¼Œä»¥æ¢ç´¢ä¸åŒçš„è§£
                q_init_noisy = q_current.copy() + (np.random.rand(model.nq) - 0.5) * noise_level
                
                # ç¡®ä¿å™ªå£°åçš„qä»åœ¨å…³èŠ‚é™åˆ¶å†…
                q_init_noisy = np.clip(q_init_noisy, model.lowerPositionLimit, model.upperPositionLimit)

                # ä½¿ç”¨å¸¦å™ªå£°çš„åˆå§‹å€¼è¿›è¡Œæ±‚è§£
                success, q_ik, err = compute_ik(model, data, world_position, world_euler_angles, q_init_noisy, active_idxs)
                solutions.append(q_ik)
                errors.append(err)
            # --- æ–¹æ¡ˆä¸€ä¿®æ”¹ç»“æŸ ---
            
            q_current, error = select_best_solution_by_error(solutions, errors, q_previous, active_idxs, per_joint_max_delta, total_max_delta, lambda_weight)
            # ğŸ”§ ä¿è¯éæœºæ¢°è‡‚å…³èŠ‚ä¸åŠ¨
            mask = np.ones(model.nq, dtype=bool)
            mask[active_idxs] = False
            q_current[mask] = q_start[mask]    
        print(f"Frame {i}: Joint Angles: {q_current[active_idxs]}, Error: {error}")
        viz.display(q_current)
        
        target_pose = pin.SE3(world_rotation, world_position)
        
        viz.viewer["target_sphere"].set_object(g.Sphere(0.05), g.MeshLambertMaterial(color=0xff0000, opacity=0.8))
        viz.viewer["target_sphere"].set_transform(tf.translation_matrix(world_position))
        
        axis_length = 0.15
        x_points = np.array([[0, axis_length], [0, 0], [0, 0]])
        y_points = np.array([[0, 0], [0, axis_length], [0, 0]])
        z_points = np.array([[0, 0], [0, 0], [0, axis_length]])
        
        viz.viewer["target_axes/x"].set_object(g.Line(g.PointsGeometry(x_points), g.MeshBasicMaterial(color=0xff0000)))
        viz.viewer["target_axes/y"].set_object(g.Line(g.PointsGeometry(y_points), g.MeshBasicMaterial(color=0xffff00)))
        viz.viewer["target_axes/z"].set_object(g.Line(g.PointsGeometry(z_points), g.MeshBasicMaterial(color=0x0000ff)))
        
        target_tf = target_pose.homogeneous
        viz.viewer["target_axes/x"].set_transform(target_tf)
        viz.viewer["target_axes/y"].set_transform(target_tf)
        viz.viewer["target_axes/z"].set_transform(target_tf)
        
        print(f"Frame {i} å¯è§†åŒ–æ›´æ–°ï¼šè§‚å¯Ÿæµè§ˆå™¨ä¸­æœºæ¢°è‡‚ (å½“å‰ q) ä¸çº¢è‰²çƒä½“åŠåæ ‡è½´ (ç›®æ ‡) çš„å·®è·ã€‚")
        
        time.sleep(2)

        pin.forwardKinematics(model, data, q_current)
        pin.updateFramePlacements(model, data)
        current_pose = data.oMf[model.getFrameId("r_gripper_base_link")]
        print(f"å½“å‰æœ«ç«¯ä½ç½®: {current_pose.translation}, ç›®æ ‡ä½ç½® (ä¸–ç•Œ): {world_position}")
        print(f"Frame {i} çº¢è‰²å°çƒä½ç½® (æœ¬åœ°): {position}")
        print(f"Frame {i} çº¢è‰²å°çƒä½ç½® (ä¸–ç•Œ): {world_position}")

if __name__ == "__main__":
    main()